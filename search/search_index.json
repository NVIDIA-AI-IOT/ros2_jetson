{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ROS2 Support on NVIDIA Jetson This page enumerates all the new updates for ROS2 including AI ROS2 packages Cuda library support Docker containers, Blogs and presentation slides many more things coming along!! This work is licensed under a Creative Commons Attribution 4.0 International License","title":"Home"},{"location":"#ros2-support-on-nvidia-jetson","text":"This page enumerates all the new updates for ROS2 including AI ROS2 packages Cuda library support Docker containers, Blogs and presentation slides many more things coming along!! This work is licensed under a Creative Commons Attribution 4.0 International License","title":"ROS2 Support on NVIDIA Jetson"},{"location":"about/","text":"For ros2-jetson","title":"About"},{"location":"blogs/","text":"ROS2 Blogs This page provides blogs published by NVIDIA for ROS/ROS2 Support on NVIDIA Jetson developer kits. Blogs Training Your NVIDIA JetBot to Avoid Collisions Using NVIDIA Isaac Sim Implementing Robotics Applications with ROS 2 and AI on the NVIDIA Jetson Platform Use CUDA PCL 1.0 to accelerate Jetson's point cloud processing Slides Edge AI Working Group Meeting \u2014 December 3rd 2020 This work is licensed under a Creative Commons Attribution 4.0 International License","title":"Blogs"},{"location":"blogs/#ros2-blogs","text":"This page provides blogs published by NVIDIA for ROS/ROS2 Support on NVIDIA Jetson developer kits.","title":"ROS2 Blogs"},{"location":"blogs/#blogs","text":"Training Your NVIDIA JetBot to Avoid Collisions Using NVIDIA Isaac Sim Implementing Robotics Applications with ROS 2 and AI on the NVIDIA Jetson Platform Use CUDA PCL 1.0 to accelerate Jetson's point cloud processing","title":"Blogs"},{"location":"blogs/#slides","text":"Edge AI Working Group Meeting \u2014 December 3rd 2020 This work is licensed under a Creative Commons Attribution 4.0 International License","title":"Slides"},{"location":"libraries/","text":"ROS / ROS2 supported libraries on NVIDIA Jetson cuda-pcl : CUDA Accelerated PointCloud Library on Jetson Many Jetson users choose lidar for positioning and sensing in automation solutions. Lidar uses a 3D point cloud to depict the surrounding space environment. The point cloud can sample the surface information of the object with high precision and long distance to facilitate the obstacle perception, mapping, positioning and path planning algorithms of the upper application. NVIDIA-AI-IOT/cuda-pcl GitHub Link cuda-pcl has some libraries used to process points cloud with CUDA and some samples for their usage. The are several subfolders in the project and every subfolder has: * lib for segmentation implemented by CUDA * Sample code can show the lib usage and also be used to check perf and accuracy by comparing its output with PCL This work is licensed under a Creative Commons Attribution 4.0 International License","title":"Libraries"},{"location":"libraries/#ros-ros2-supported-libraries-on-nvidia-jetson","text":"","title":"ROS / ROS2 supported libraries on NVIDIA Jetson"},{"location":"libraries/#cuda-pcl-cuda-accelerated-pointcloud-library-on-jetson","text":"Many Jetson users choose lidar for positioning and sensing in automation solutions. Lidar uses a 3D point cloud to depict the surrounding space environment. The point cloud can sample the surface information of the object with high precision and long distance to facilitate the obstacle perception, mapping, positioning and path planning algorithms of the upper application. NVIDIA-AI-IOT/cuda-pcl GitHub Link cuda-pcl has some libraries used to process points cloud with CUDA and some samples for their usage. The are several subfolders in the project and every subfolder has: * lib for segmentation implemented by CUDA * Sample code can show the lib usage and also be used to check perf and accuracy by comparing its output with PCL This work is licensed under a Creative Commons Attribution 4.0 International License","title":"cuda-pcl : CUDA Accelerated PointCloud Library on Jetson"},{"location":"ros2-jetson-dockers/","text":"ROS2 Docker Containers for NVIDIA Jetson Docker Containers for ROS/ROS2 GitHub Link This repository is created for ROS Noetic and ROS2 Foxy / Eloquent containers for NVIDIA Jetson platform based on ROS2 Installation Guide , ROS Noetic Installing from Source , and dusty-nv/jetson-containers This repository supports following docker images: ROS2 Eloquent / Foxy, and ROS Noetic with PyTorch and TensorRT DL Libraries: PyTorch, NVIDIA TensorRT ML Libraries: scikit-learn, numpy etc Cuda Acceleration Library: pyCUDA Widely used developer repositories: torch2trt, trt_pose ROS2 Packages: (Foxy packages will be updated soon) NVIDIA-AI-IOT/ros2_trt_pose NVIDIA-AI-IOT/ros2_trt_pose_hand ROS2 Eloquent / Foxy with DeepStream SDK NVIDIA DeepStream SDK for Classification, Object detection ROS2 packages: (Foxy packages will be updated soon) NVIDIA-AI-IOT/ros2_deepstream vision_msgs Pull Docker Images DockerFiles for ROS/ROS2, ML Libraries dusty-nv/jetson-containers GitHub Link To easily run different versions of ROS 2 on Jetson, NVIDIA has released various Dockerfiles and build scripts for ROS 2 Eloquent and Foxy, in addition to ROS Melodic and Noetic. These containers provide an automated and reliable way to install ROS or ROS 2 on Jetson and build your own ROS-based applications. Because Eloquent and Melodic already provide prebuilt packages for Ubuntu 18.04, these versions of ROS are installed into the containers by the Dockerfiles. On the other hand, Foxy and Noetic are built from a source inside the container as those versions only come prebuilt for Ubuntu 20.04. With the containers, using these versions of ROS or ROS 2 is the same, regardless of the underlying OS distribution. This work is licensed under a Creative Commons Attribution 4.0 International License","title":"Containers"},{"location":"ros2-jetson-dockers/#ros2-docker-containers-for-nvidia-jetson","text":"","title":"ROS2 Docker Containers for NVIDIA Jetson"},{"location":"ros2-jetson-dockers/#docker-containers-for-rosros2","text":"GitHub Link This repository is created for ROS Noetic and ROS2 Foxy / Eloquent containers for NVIDIA Jetson platform based on ROS2 Installation Guide , ROS Noetic Installing from Source , and dusty-nv/jetson-containers This repository supports following docker images: ROS2 Eloquent / Foxy, and ROS Noetic with PyTorch and TensorRT DL Libraries: PyTorch, NVIDIA TensorRT ML Libraries: scikit-learn, numpy etc Cuda Acceleration Library: pyCUDA Widely used developer repositories: torch2trt, trt_pose ROS2 Packages: (Foxy packages will be updated soon) NVIDIA-AI-IOT/ros2_trt_pose NVIDIA-AI-IOT/ros2_trt_pose_hand ROS2 Eloquent / Foxy with DeepStream SDK NVIDIA DeepStream SDK for Classification, Object detection ROS2 packages: (Foxy packages will be updated soon) NVIDIA-AI-IOT/ros2_deepstream vision_msgs Pull Docker Images","title":"Docker Containers for ROS/ROS2"},{"location":"ros2-jetson-dockers/#dockerfiles-for-rosros2-ml-libraries","text":"dusty-nv/jetson-containers GitHub Link To easily run different versions of ROS 2 on Jetson, NVIDIA has released various Dockerfiles and build scripts for ROS 2 Eloquent and Foxy, in addition to ROS Melodic and Noetic. These containers provide an automated and reliable way to install ROS or ROS 2 on Jetson and build your own ROS-based applications. Because Eloquent and Melodic already provide prebuilt packages for Ubuntu 18.04, these versions of ROS are installed into the containers by the Dockerfiles. On the other hand, Foxy and Noetic are built from a source inside the container as those versions only come prebuilt for Ubuntu 20.04. With the containers, using these versions of ROS or ROS 2 is the same, regardless of the underlying OS distribution. This work is licensed under a Creative Commons Attribution 4.0 International License","title":"DockerFiles for ROS/ROS2, ML Libraries"},{"location":"ros2-packages/","text":"ROS2 Packages on NVIDIA Jetson Ease of use and deployment have made the NVIDIA Jetson platform a logical choice for developers, researchers, and manufacturers building and deploying robots. ROS2 Package for Accelerated AprilTags NVIDIA-AI-IOT/ros2-nvapriltags GitHub Link AprilTags is a common fiducial tag that makes it easy to derive its 6DOF pose of in a scene with only a monocular camera. These tags are used in a variety of applications in robotics such as object tracking and visual localization. The faster one can detect the pose of a tag, the faster the closed loop can be for more responsive behaviors. Native ROS2 package wraps NVIDIA's GPU-accelerated AprilTag detector for fast detection of the 36h11 tag family published as a standard TF topic. The underlying NVAprilTag library is still in development, so please validate its performance for your use cases. Feedback is appreciated. ROS2 node uses the NVIDIA GPU-accelerated AprilTags library to detect AprilTags in images and publish their poses, ids, and additional metadata. This has been tested on ROS2 (Foxy) and should run on x86_64 and aarch64 (Jetson hardware). It is modeled after and comparable to the ROS2 node for CPU AprilTags detection For more information on the Isaac GEM this node is based off of, see the Isaac SDK 2020.2 documentation For more information on AprilTags themselves, the paper and the reference CPU implementation: please check UMICH Apriltag ROS2 Package for Human Hand Pose Estimation The ros2_trt_pose_hand package is implemented based on trt_pose_hand , which implements a real-time hand pose estimation and gesture classification using TensorRT. NVIDIA-AI-IOT/ros2-trt-pose-hand GitHub Link Here are the key features of the ros2_trt_pose_hand package: Hand Pose message with 21 key-points Hand Pose detection image message std_msgs for gesture classification with 6 classes [fist, pan, stop, fine, peace, no hand] Visualization markers Launch file for RViz ROS2 Package for Human Pose Estimation The ros2_trt_pose package is implemented based on trt_pose , which enables pose estimation on the Jetson platform. The repository provides two trained models for pose estimation using resnet18 and densenet121. To understand human pose, pretrained models infer 17 body parts based on the categories from the COCO dataset. NVIDIA-AI-IOT/ros2-trt-pose GitHub Link Here are the key features of the ros2_trt_pose package: Publishes pose_msgs such as count of person and person_id . For each person_id , it publishes 17 body parts. Provides launch file for easy usage and visualizations on Rviz2: Image messages Visual markers: body_joints , body_skeleton Contains a Jetson-based Docker image for easy install and usage ROS2 Package for PyTorch and NVIDIA TensorRT There are two packages for classification and detection using PyTorch, each with their corresponding TRT versions implemented. These four packages are a good starting point for roboticists using ROS 2 to get started with deep learning using PyTorch. TensorRT has been integrated into the packages with the help of torch2trt for accelerated inference. It generates a runtime engine which is optimized according to the architecture of the network and the deployment device. NVIDIA-AI-IOT/ros2-torch-trt GitHub Link The main features of the packages are as follows: For classification, you can select from various ImageNet pretrained models, including Resnet18, AlexNet, SqueezeNet, and Resnet50. For detection, MobileNetV1-based SSD is currently supported, trained on the COCO dataset. The TRT packages provide a significant speedup in carrying out inference relative to the PyTorch models performing inference directly on the GPU. The inference results are published in the form of vision_msgs . On running the node, a window is also shown with the inference results visualized. A Jetson-based Docker image and launch file is provided for ease of use ROS 2 Package for DeepStream SDK The DeepStream SDK delivers a complete streaming analytics toolkit to build end-to-end AI-based solutions using multi-sensor processing, video, and image understanding. It offers support for popular object detection and segmentation models such as state of the art SSD, YOLO, FasterRCNN, and MaskRCNN. NVIDIA-AI-IOT/ros2-deepstream GitHub Link NVIDIA provide ROS 2 nodes that perform two inference tasks based on the DeepStream Python Apps project as follows: Object detection: Four classes of objects are detected: Vehicle, Person, RoadSign, and TwoWheeler. Attribute classification: Three types of attributes are classified for objects of class Vehicle: Color, Make, and Type. These publisher nodes take single or multiple video streams as input from camera or file. They perform inference and publish results of detection and classification to different topics. We also provide sample ROS 2 subscriber nodes that subscribe to these topics and display results in vision_msgs format. Each inference task also spawns a visualization window with bounding boxes and labels around detected objects. Additional inference tasks and custom models can be integrated with the DeepStream pipeline provided in this project. ROS2 Package for Jetson Stats The ros2_jetson_stats package is a community build package that monitors and controls your Jetson device. It can run on your terminal and provides a Python package for easy integration in Python scripts. Take advantage of the ros2_jetson_stats library and build ROS 2 diagnostic messages and services. NVIDIA-AI-IOT/ros2-jetson-stats GitHub Link The ros2_jetson_stats package features the following ROS 2 diagnostic messages: GPU/CPU usage percentage EMC/SWAP/Memory status (% usage) Power and temperature of SoC You can now control the following through the ROS 2 command line: Fan (Mode and Speed) Power model (nvpmodel) jetson_clocks You can also provide a parameter to set the frequency of reading diagnostic messages. Deep Learning Nodes for ROS/ROS2 This repo contains deep learning inference nodes and camera/video streaming nodes for ROS/ROS2 with support for Jetson Nano/TX1/TX2/Xavier NX/AGX Xavier and TensorRT. GitHub Link The nodes use the image recognition, object detection, and semantic segmentation DNN's from the jetson-inference library and NVIDIA Hello AI World tutorial, which come with several built-in pretrained networks for classification, detection, and segmentation and the ability to load customized user-trained models. The camera/video streaming nodes support the following input/output interfaces: MIPI CSI cameras V4L2 cameras RTP / RTSP Videos & Images Image sequences OpenGL windows ROS Melodic and ROS2 Eloquent are supported, and the latest version of JetPack is recommended. This work is licensed under a Creative Commons Attribution 4.0 International License","title":"ROS2_packages"},{"location":"ros2-packages/#ros2-packages-on-nvidia-jetson","text":"Ease of use and deployment have made the NVIDIA Jetson platform a logical choice for developers, researchers, and manufacturers building and deploying robots.","title":"ROS2 Packages on NVIDIA Jetson"},{"location":"ros2-packages/#ros2-package-for-accelerated-apriltags","text":"NVIDIA-AI-IOT/ros2-nvapriltags GitHub Link AprilTags is a common fiducial tag that makes it easy to derive its 6DOF pose of in a scene with only a monocular camera. These tags are used in a variety of applications in robotics such as object tracking and visual localization. The faster one can detect the pose of a tag, the faster the closed loop can be for more responsive behaviors. Native ROS2 package wraps NVIDIA's GPU-accelerated AprilTag detector for fast detection of the 36h11 tag family published as a standard TF topic. The underlying NVAprilTag library is still in development, so please validate its performance for your use cases. Feedback is appreciated. ROS2 node uses the NVIDIA GPU-accelerated AprilTags library to detect AprilTags in images and publish their poses, ids, and additional metadata. This has been tested on ROS2 (Foxy) and should run on x86_64 and aarch64 (Jetson hardware). It is modeled after and comparable to the ROS2 node for CPU AprilTags detection For more information on the Isaac GEM this node is based off of, see the Isaac SDK 2020.2 documentation For more information on AprilTags themselves, the paper and the reference CPU implementation: please check UMICH Apriltag","title":"ROS2 Package for Accelerated AprilTags"},{"location":"ros2-packages/#ros2-package-for-human-hand-pose-estimation","text":"The ros2_trt_pose_hand package is implemented based on trt_pose_hand , which implements a real-time hand pose estimation and gesture classification using TensorRT. NVIDIA-AI-IOT/ros2-trt-pose-hand GitHub Link Here are the key features of the ros2_trt_pose_hand package: Hand Pose message with 21 key-points Hand Pose detection image message std_msgs for gesture classification with 6 classes [fist, pan, stop, fine, peace, no hand] Visualization markers Launch file for RViz","title":"ROS2 Package for Human Hand Pose Estimation"},{"location":"ros2-packages/#ros2-package-for-human-pose-estimation","text":"The ros2_trt_pose package is implemented based on trt_pose , which enables pose estimation on the Jetson platform. The repository provides two trained models for pose estimation using resnet18 and densenet121. To understand human pose, pretrained models infer 17 body parts based on the categories from the COCO dataset. NVIDIA-AI-IOT/ros2-trt-pose GitHub Link Here are the key features of the ros2_trt_pose package: Publishes pose_msgs such as count of person and person_id . For each person_id , it publishes 17 body parts. Provides launch file for easy usage and visualizations on Rviz2: Image messages Visual markers: body_joints , body_skeleton Contains a Jetson-based Docker image for easy install and usage","title":"ROS2 Package for Human Pose Estimation"},{"location":"ros2-packages/#ros2-package-for-pytorch-and-nvidia-tensorrt","text":"There are two packages for classification and detection using PyTorch, each with their corresponding TRT versions implemented. These four packages are a good starting point for roboticists using ROS 2 to get started with deep learning using PyTorch. TensorRT has been integrated into the packages with the help of torch2trt for accelerated inference. It generates a runtime engine which is optimized according to the architecture of the network and the deployment device. NVIDIA-AI-IOT/ros2-torch-trt GitHub Link The main features of the packages are as follows: For classification, you can select from various ImageNet pretrained models, including Resnet18, AlexNet, SqueezeNet, and Resnet50. For detection, MobileNetV1-based SSD is currently supported, trained on the COCO dataset. The TRT packages provide a significant speedup in carrying out inference relative to the PyTorch models performing inference directly on the GPU. The inference results are published in the form of vision_msgs . On running the node, a window is also shown with the inference results visualized. A Jetson-based Docker image and launch file is provided for ease of use","title":"ROS2 Package for PyTorch and NVIDIA TensorRT"},{"location":"ros2-packages/#ros-2-package-for-deepstream-sdk","text":"The DeepStream SDK delivers a complete streaming analytics toolkit to build end-to-end AI-based solutions using multi-sensor processing, video, and image understanding. It offers support for popular object detection and segmentation models such as state of the art SSD, YOLO, FasterRCNN, and MaskRCNN. NVIDIA-AI-IOT/ros2-deepstream GitHub Link NVIDIA provide ROS 2 nodes that perform two inference tasks based on the DeepStream Python Apps project as follows: Object detection: Four classes of objects are detected: Vehicle, Person, RoadSign, and TwoWheeler. Attribute classification: Three types of attributes are classified for objects of class Vehicle: Color, Make, and Type. These publisher nodes take single or multiple video streams as input from camera or file. They perform inference and publish results of detection and classification to different topics. We also provide sample ROS 2 subscriber nodes that subscribe to these topics and display results in vision_msgs format. Each inference task also spawns a visualization window with bounding boxes and labels around detected objects. Additional inference tasks and custom models can be integrated with the DeepStream pipeline provided in this project.","title":"ROS 2 Package for DeepStream SDK"},{"location":"ros2-packages/#ros2-package-for-jetson-stats","text":"The ros2_jetson_stats package is a community build package that monitors and controls your Jetson device. It can run on your terminal and provides a Python package for easy integration in Python scripts. Take advantage of the ros2_jetson_stats library and build ROS 2 diagnostic messages and services. NVIDIA-AI-IOT/ros2-jetson-stats GitHub Link The ros2_jetson_stats package features the following ROS 2 diagnostic messages: GPU/CPU usage percentage EMC/SWAP/Memory status (% usage) Power and temperature of SoC You can now control the following through the ROS 2 command line: Fan (Mode and Speed) Power model (nvpmodel) jetson_clocks You can also provide a parameter to set the frequency of reading diagnostic messages.","title":"ROS2 Package for Jetson Stats"},{"location":"ros2-packages/#deep-learning-nodes-for-rosros2","text":"This repo contains deep learning inference nodes and camera/video streaming nodes for ROS/ROS2 with support for Jetson Nano/TX1/TX2/Xavier NX/AGX Xavier and TensorRT. GitHub Link The nodes use the image recognition, object detection, and semantic segmentation DNN's from the jetson-inference library and NVIDIA Hello AI World tutorial, which come with several built-in pretrained networks for classification, detection, and segmentation and the ability to load customized user-trained models. The camera/video streaming nodes support the following input/output interfaces: MIPI CSI cameras V4L2 cameras RTP / RTSP Videos & Images Image sequences OpenGL windows ROS Melodic and ROS2 Eloquent are supported, and the latest version of JetPack is recommended. This work is licensed under a Creative Commons Attribution 4.0 International License","title":"Deep Learning Nodes for ROS/ROS2"}]}