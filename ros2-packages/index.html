
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../images/favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.2.5">
    
    
      
        <title>Packages - isaac-ros2</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.15aa0b43.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.75751829.min.css">
        
          
          
          <meta name="theme-color" content="#4cae4f">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="green" data-md-color-accent="">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ros2-packages-on-nvidia-jetson" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="isaac-ros2" class="md-header-nav__button md-logo" aria-label="isaac-ros2">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      <div class="md-header-nav__ellipsis">
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            isaac-ros2
          </span>
        </div>
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            
              Packages
            
          </span>
        </div>
      </div>
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="isaac-ros2" class="md-nav__button md-logo" aria-label="isaac-ros2">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    isaac-ros2
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      


  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Packages
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Packages
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ros2-isaac-ros-image_pipeline" class="md-nav__link">
    ROS2: Isaac ROS image_pipeline
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-isaac-ros-common" class="md-nav__link">
    ROS2: Isaac ROS Common
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-accelerated-apriltags" class="md-nav__link">
    ROS2 Package for Accelerated AprilTags
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-human-hand-pose-estimation" class="md-nav__link">
    ROS2 Package for Human Hand Pose Estimation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-human-pose-estimation" class="md-nav__link">
    ROS2 Package for Human Pose Estimation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-pytorch-and-nvidia-tensorrt" class="md-nav__link">
    ROS2 Package for PyTorch and NVIDIA TensorRT
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros-2-package-for-deepstream-sdk" class="md-nav__link">
    ROS 2 Package for DeepStream SDK
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-jetson-stats" class="md-nav__link">
    ROS2 Package for Jetson Stats
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-learning-nodes-for-rosros2" class="md-nav__link">
    Deep Learning Nodes for ROS/ROS2
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      


  
  
  
    <li class="md-nav__item">
      <a href="../ros2-jetson-dockers/" class="md-nav__link">
        Containers
      </a>
    </li>
  

    
      
      
      


  
  
  
    <li class="md-nav__item">
      <a href="../ros2-omniverse/" class="md-nav__link">
        Simulation
      </a>
    </li>
  

    
      
      
      


  
  
  
    <li class="md-nav__item">
      <a href="../libraries/" class="md-nav__link">
        Libraries
      </a>
    </li>
  

    
      
      
      


  
  
  
    <li class="md-nav__item">
      <a href="../blogs/" class="md-nav__link">
        Blogs
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ros2-isaac-ros-image_pipeline" class="md-nav__link">
    ROS2: Isaac ROS image_pipeline
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-isaac-ros-common" class="md-nav__link">
    ROS2: Isaac ROS Common
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-accelerated-apriltags" class="md-nav__link">
    ROS2 Package for Accelerated AprilTags
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-human-hand-pose-estimation" class="md-nav__link">
    ROS2 Package for Human Hand Pose Estimation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-human-pose-estimation" class="md-nav__link">
    ROS2 Package for Human Pose Estimation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-pytorch-and-nvidia-tensorrt" class="md-nav__link">
    ROS2 Package for PyTorch and NVIDIA TensorRT
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros-2-package-for-deepstream-sdk" class="md-nav__link">
    ROS 2 Package for DeepStream SDK
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ros2-package-for-jetson-stats" class="md-nav__link">
    ROS2 Package for Jetson Stats
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-learning-nodes-for-rosros2" class="md-nav__link">
    Deep Learning Nodes for ROS/ROS2
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="ros2-packages-on-nvidia-jetson">ROS2 Packages on NVIDIA Jetson</h1>
<p>Ease of use and deployment have made the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson platform</a> a logical choice for developers, researchers, and manufacturers building and deploying robots.</p>
<h2 id="ros2-isaac-ros-image_pipeline">ROS2: Isaac ROS image_pipeline</h2>
<p><a href="https://github.com/NVIDIA-AI-IOT/isaac_ros_image_pipeline">NVIDIA-AI-IOT/isaac-ros-image-pipeline</a></p>
<p>This metapackage offers similar functionality as the standard, CPU-based <a href="http://wiki.ros.org/image_pipeline">image_pipeline metapackage</a>, but does so by leveraging the Jetson platform's specialized computer vision hardware. Considerable effort has been made to ensure that replacing image_pipeline with isaac_ros_image_pipeline on a Jetson device is as painless a transition as possible.</p>
<h2 id="ros2-isaac-ros-common">ROS2: Isaac ROS Common</h2>
<p><a href="https://github.com/NVIDIA-AI-IOT/isaac_ros_common">NVIDIA-AI-IOT/isaac-ros-common</a></p>
<p>Isaac ROS common utilities for use in conjunction with the Isaac ROS suite of packages. <br/>
Note: Please refer to scripts/README.md for script used to setup dev environment.</p>
<h2 id="ros2-package-for-accelerated-apriltags">ROS2 Package for Accelerated AprilTags</h2>
<p><a href="https://github.com/NVIDIA-AI-IOT/ros2-nvapriltags">NVIDIA-AI-IOT/ros2-nvapriltags GitHub Link</a></p>
<p>AprilTags is a common fiducial tag that makes it easy to derive its 6DOF pose of in a scene with only a monocular camera. These tags are used in a variety of applications in robotics such as object tracking and visual localization. The faster one can detect the pose of a tag, the faster the closed loop can be for more responsive behaviors. Native ROS2 package wraps NVIDIA's GPU-accelerated AprilTag detector for fast detection of the 36h11 tag family published as a standard TF topic.</p>
<p>The underlying NVAprilTag library is still in development, so please validate its performance for your use cases. Feedback is appreciated.</p>
<p>ROS2 node uses the NVIDIA GPU-accelerated AprilTags library to detect AprilTags in images and publish their poses, ids, and additional metadata. This has been tested on ROS2 (Foxy) and should run on x86_64 and aarch64 (Jetson hardware). It is modeled after and comparable to the ROS2 node for <a href="https://github.com/christianrauch/apriltag_ros.git">CPU AprilTags detection</a></p>
<p>For more information on the Isaac GEM this node is based off of, see the <a href="https://docs.nvidia.com/isaac/isaac/packages/fiducials/doc/apriltags.html">Isaac SDK 2020.2 documentation</a></p>
<p>For more information on AprilTags themselves, the paper and the reference CPU implementation: please check <a href="https://april.eecs.umich.edu/software/apriltag.html">UMICH Apriltag</a></p>
<h2 id="ros2-package-for-human-hand-pose-estimation">ROS2 Package for Human Hand Pose Estimation</h2>
<p>The <code>ros2_trt_pose_hand</code> package is implemented based on <code>trt_pose_hand</code>, which implements a real-time hand pose estimation and gesture classification using TensorRT.</p>
<p><a href="https://github.com/NVIDIA-AI-IOT/ros2_trt_pose_hand"> NVIDIA-AI-IOT/ros2-trt-pose-hand GitHub Link</a></p>
<p>Here are the key features of the <code>ros2_trt_pose_hand</code> package:</p>
<ul>
<li>Hand Pose message with 21 key-points</li>
<li>Hand Pose detection image message</li>
<li><code>std_msgs</code> for gesture classification with 6 classes [fist, pan, stop, fine, peace, no hand]</li>
<li>Visualization markers</li>
<li>Launch file for RViz</li>
</ul>
<h2 id="ros2-package-for-human-pose-estimation">ROS2 Package for Human Pose Estimation</h2>
<p>The <code>ros2_trt_pose</code> package is implemented based on <code>trt_pose</code>, which enables pose estimation on the Jetson platform. The repository provides two trained models for pose estimation using resnet18 and densenet121. To understand human pose, pretrained models infer 17 body parts based on the categories from the COCO dataset.</p>
<p><a href="https://github.com/NVIDIA-AI-IOT/ros2_trt_pose"> NVIDIA-AI-IOT/ros2-trt-pose GitHub Link</a></p>
<p>Here are the key features of the <code>ros2_trt_pose</code> package:</p>
<ul>
<li>Publishes <code>pose_msgs</code> such as count of person and <code>person_id</code>. For each <code>person_id</code>, it publishes 17 body parts.</li>
<li>Provides launch file for easy usage and visualizations on Rviz2:
<strong> Image messages
</strong> Visual markers: <code>body_joints</code>, <code>body_skeleton</code></li>
<li>Contains a Jetson-based Docker image for easy install and usage</li>
</ul>
<h2 id="ros2-package-for-pytorch-and-nvidia-tensorrt">ROS2 Package for PyTorch and NVIDIA TensorRT</h2>
<p>There are two packages for classification and detection using PyTorch, each with their corresponding TRT versions implemented. These four packages are a good starting point for roboticists using ROS 2 to get started with deep learning using PyTorch.</p>
<p>TensorRT has been integrated into the packages with the help of torch2trt for accelerated inference. It generates a runtime engine which is optimized according to the architecture of the network and the deployment device.   </p>
<p><a href="https://github.com/NVIDIA-AI-IOT/ros2_torch_trt">NVIDIA-AI-IOT/ros2-torch-trt GitHub Link</a></p>
<p>The main features of the packages are as follows:</p>
<ul>
<li>For classification, you can select from various ImageNet pretrained models, including Resnet18, AlexNet, SqueezeNet, and Resnet50.</li>
<li>For detection, MobileNetV1-based SSD is currently supported, trained on the COCO dataset.</li>
<li>The TRT packages provide a significant speedup in carrying out inference relative to the PyTorch models performing inference directly on the GPU.</li>
<li>The inference results are published in the form of <code>vision_msgs</code>.</li>
<li>On running the node, a window is also shown with the inference results visualized.</li>
<li>A Jetson-based Docker image and launch file is provided for ease of use</li>
</ul>
<h2 id="ros-2-package-for-deepstream-sdk">ROS 2 Package for DeepStream SDK</h2>
<p>The DeepStream SDK delivers a complete streaming analytics toolkit to build end-to-end AI-based solutions using multi-sensor processing, video, and image understanding. It offers support for popular object detection and segmentation models such as state of the art SSD, YOLO, FasterRCNN, and MaskRCNN.</p>
<p><a href="https://github.com/NVIDIA-AI-IOT/ros2_deepstream">NVIDIA-AI-IOT/ros2-deepstream GitHub Link</a></p>
<p>NVIDIA provide ROS 2 nodes that perform two inference tasks based on the DeepStream Python Apps project as follows:</p>
<ul>
<li>Object detection: Four classes of objects are detected: Vehicle, Person, RoadSign, and TwoWheeler.</li>
<li>Attribute classification: Three types of attributes are classified for objects of class Vehicle: Color, Make, and Type.</li>
</ul>
<p>These publisher nodes take single or multiple video streams as input from camera or file. They perform inference and publish results of detection and classification to different topics. We also provide sample ROS 2 subscriber nodes that subscribe to these topics and display results in <code>vision_msgs</code> format. Each inference task also spawns a visualization window with bounding boxes and labels around detected objects. Additional inference tasks and custom models can be integrated with the DeepStream pipeline provided in this project.</p>
<h2 id="ros2-package-for-jetson-stats">ROS2 Package for Jetson Stats</h2>
<p>The <code>ros2_jetson_stats</code> package is a community build package that monitors and controls your Jetson device. It can run on your terminal and provides a Python package for easy integration in Python scripts. Take advantage of the <code>ros2_jetson_stats</code> library and build ROS 2 diagnostic messages and services.</p>
<p><a href="https://github.com/NVIDIA-AI-IOT/ros2_jetson_stats">NVIDIA-AI-IOT/ros2-jetson-stats GitHub Link</a></p>
<p>The <code>ros2_jetson_stats</code> package features the following ROS 2 diagnostic messages:</p>
<ul>
<li>GPU/CPU usage percentage</li>
<li>EMC/SWAP/Memory status (% usage)</li>
<li>Power and temperature of SoC</li>
</ul>
<p>You can now control the following through the ROS 2 command line:</p>
<ul>
<li>Fan (Mode and Speed)</li>
<li>Power model (nvpmodel)</li>
<li><code>jetson_clocks</code>
You can also provide a parameter to set the frequency of reading diagnostic messages.</li>
</ul>
<h2 id="deep-learning-nodes-for-rosros2">Deep Learning Nodes for ROS/ROS2</h2>
<p>This repo contains deep learning inference nodes and camera/video streaming nodes for ROS/ROS2 with support for Jetson Nano/TX1/TX2/Xavier NX/AGX Xavier and TensorRT.</p>
<p><a href="https://github.com/dusty-nv/ros_deep_learning">GitHub Link</a></p>
<p>The nodes use the image recognition, object detection, and semantic segmentation DNN's from the <code>jetson-inference</code> library and <a href="https://developer.nvidia.com/embedded/twodaystoademo">NVIDIA Hello AI World</a> tutorial, which come with several built-in pretrained networks for classification, detection, and segmentation and the ability to load customized user-trained models.</p>
<p>The camera/video streaming nodes support the following input/output interfaces:</p>
<ul>
<li>MIPI CSI cameras</li>
<li>V4L2 cameras</li>
<li>RTP / RTSP</li>
<li>Videos &amp; Images</li>
<li>Image sequences</li>
<li>OpenGL windows</li>
</ul>
<p>ROS Melodic and ROS2 Eloquent are supported, and the latest version of JetPack is recommended.</p>
<p><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a></p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href=".." class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Home
              </div>
            </div>
          </a>
        
        
          <a href="../ros2-jetson-dockers/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Containers
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.93c04032.min.js"></script>
      <script src="../assets/javascripts/bundle.83e5331e.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.8c7e0a7e.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>